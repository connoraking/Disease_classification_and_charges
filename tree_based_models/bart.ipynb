{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aca26a3",
   "metadata": {},
   "source": [
    "# Bayesian Additive Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97d456",
   "metadata": {},
   "source": [
    "In this notebook, we will use the machine learning model of *Bayesian Additive Regression Tree* (BART)\n",
    "\n",
    "BART is related to both random forests and boosting: each tree is constructed in a random manner (bagging and random forests) and each tree tries to capture signal not yet accounted for by the current model (boosting)\n",
    "\n",
    "$1$ to $K$ regressive trees are fit in parallel and each tree is changed $B$ times as the sequential algorithm proceeds. At each step, the $K$ trees are changed in some way (*pertubrations*). At the nodes we can add or remove a branch or change the predicted values at each of th nodes. Basically we maintain $K$ trees and at each iteration we change each of those $K$ trees in some random way.\n",
    "\n",
    "$\\hat{f}^b_k(x)$ represents the prediction at $x$ for the $k$-th regression tree used in the $b$-th iteration. At the end of each iteration, the $K$ trees from that iteration will be summed: $\\hat{f}^{b}(x) = \\sum_{k=1}^{K}\\hat{f}^b_k(x)$ for $b = 1, \\dots, B$\n",
    "\n",
    "For the *first iteration* of BART, all trees are initialized to have a single root node as the mean response values divded by the total number of trees: $\\hat{f}^1_k(x) = \\frac{1}{nK}\\sum^{n}_{i=1}y_i$ thus $\\hat{f}^1(x) = \\frac{1}{n}\\sum^{n}_{i=1}y_i$\n",
    "\n",
    "After the first iteration: the $b$-th iteration, to update the $k$-th tree, we subtract from each response value the predictions from all **but** the $k$-th tree in order to obtain a *partial residual*:\n",
    "\n",
    "$$r_i = y_i - \\sum_{k'< k}\\hat{f}^b_{k'}(x_i) - \\sum_{k'>k}\\hat{f}^{b-1}_{k'}(x_i)$$\n",
    "\n",
    "Rather than fitting a fresh tree to this partial residual, BART randomly chooses a *pertubariton* to the tree from the previous iteration ($\\hat{f}^{b-1}_{k}(x)$) from a set of possible pertubations, favoring ones that improve the fit to the partial residual. As mentioned before, there are 2 different ways for this pertubation to be made:  \n",
    "\n",
    "1. Change the structure of the tree by adding or pruning branches\n",
    "2. Change the prediction in each terminal node of the tree. (Basically the final predictions are changed a tiny bit). As in the tree could predict -0.5031 at a terminal node and a pertubation would make the prediction be -0.5110 instead.\n",
    "\n",
    "To obtain a single prediction, we take the average after some $L$ *burn-in iterations*: $\\hat{f}(x) = \\frac{1}{B-L}\\sum^B_{b = L+1}\\hat{f}^b(x)$. Basically we ignore the first $L$ iterations. If $B=1000$ and $L=100$, we ignore the first $100$ steps and take the average of the remaining $900$ steps. During this period, the samples may not yet be representative of the target distribution because the chain is still \"warming up\" and finding its way to the regions of high probability density. We can also compute percenties of $f^{L+1}(x), \\dots , f^B(x)$ which provides a measure of uncertainty of the final prediction\n",
    "\n",
    "BART is a *Bayesian* algorithm because each time we randomly perturb a tree in order to fit the residuals, we are in fact draw a new tree from a *posterior* distribution. The BART algorithm can be viewed as a *Markov chain Monte Carlo* (MCMC) procedure for fitting the BART model.\n",
    "\n",
    "Typically, large values are chosen for $B$ iterations and $K$ trees and a moderate value of $L$. For instance $K= 200$, $B = 1000$, $L=100$. \n",
    "\n",
    "A drawback of BART is that it is computationally expensive and can be slow\n",
    "\n",
    "**SOURCE**: ISLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3563c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from ISLP.bart import BART\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd073579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Conno\\\\anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fcb549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607bcccd",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "116235b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing processed dataframe\n",
    "path_project = \"C:/Users/Conno/Documents/Career/Projects/Hospital_Charges/tree_based_models\"\n",
    "\n",
    "os.chdir(path_project)\n",
    "plots_dir = 'bart_plots' # stores plots in plot folder\n",
    "\n",
    "df = pd.read_csv(\"../df_processed.csv\")\n",
    "\n",
    "# do this later in data_cleaning file\n",
    "bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "df[bool_cols] = df[bool_cols].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7bdfe",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b4b1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same seed as every other mode\n",
    "X = df.drop(columns = [\"charges\"])\n",
    "y = df[\"charges\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ede161",
   "metadata": {},
   "source": [
    "# BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdbc9b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BART(burnin=200, ndraw=800, num_trees=1000, random_state=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BART</label><div class=\"sk-toggleable__content\"><pre>BART(burnin=200, ndraw=800, num_trees=1000, random_state=32)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BART(burnin=200, ndraw=800, num_trees=1000, random_state=32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ndraws is B - L, the number of iterations after the burnin\n",
    "B = 1000 # num iterations\n",
    "L = 200\n",
    "ndraws = B - L\n",
    "K = 1000 # num trees\n",
    "\n",
    "bart_model = BART(random_state = 32, burnin = L, num_trees = K, ndraw = ndraws, n_jobs = -1)\n",
    "bart_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59b646",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7416fa7",
   "metadata": {},
   "source": [
    "We will track feature importance by checking how many times each predictor (feature) appeared in the collection of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a9af492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hday                          43.34250\n",
       "slos                          39.21875\n",
       "dnrday                        38.58125\n",
       "scoma                         38.57750\n",
       "hospdead                      36.69500\n",
       "dzgroup_chf                   36.18375\n",
       "dzgroup_colon_cancer          36.03375\n",
       "dzclass_cancer                35.74000\n",
       "d_time                        35.64250\n",
       "surv2m                        35.59250\n",
       "dzgroup_lung_cancer           35.55500\n",
       "sfdm2_adl>=4_>=5_if_sur_      35.43375\n",
       "avtisst                       35.42875\n",
       "dzgroup_copd                  34.61625\n",
       "dzclass_copd_chf_cirrhosis    34.46500\n",
       "num_co                        34.43500\n",
       "surv6m                        34.38250\n",
       "prg2m                         34.23250\n",
       "dzclass_coma                  33.79500\n",
       "dzgroup_mosf_w_malig          33.79500\n",
       "sps                           33.66500\n",
       "dzgroup_coma                  33.56500\n",
       "aps                           33.47000\n",
       "prg6m                         33.38875\n",
       "dzgroup_cirrhosis             32.76875\n",
       "sfdm2_no_m2_and_sip_pres_     32.17500\n",
       "ca_yes                        31.45375\n",
       "sfdm2_sip>=30                 31.08250\n",
       "dementia                      29.82250\n",
       "adlsc                         29.65625\n",
       "edu                           29.58375\n",
       "dnr_no_dnr                    29.42000\n",
       "age                           29.26500\n",
       "race_hispanic                 29.13750\n",
       "diabetes                      29.10250\n",
       "death                         28.77500\n",
       "dnr_dnr_before_sadm           28.39125\n",
       "ca_no                         28.06375\n",
       "race_black                    25.61250\n",
       "hrt                           25.59125\n",
       "race_white                    25.24750\n",
       "resp                          25.06625\n",
       "crea                          25.03250\n",
       "meanbp                        24.35000\n",
       "temp                          24.02500\n",
       "wblc                          23.85625\n",
       "sex_male                      23.56625\n",
       "sod                           21.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_inclusion = pd.Series(bart_model.variable_inclusion_.mean(0),\n",
    "                         index = X.columns).sort_values(ascending = False)\n",
    "var_inclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba51a4",
   "metadata": {},
   "source": [
    "The feature importance is similar to *bagging* and *random forest*, however `hday` was the most importance predictor meanwhile `slos` was the mort important for both *bagging* and *random forest*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86682576",
   "metadata": {},
   "source": [
    "## Predicting Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49797c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bart = bart_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e7c1f52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART MAPE: 0.9437\n",
      "BART MAE: 28367.4678\n",
      "BART MSE: 3549067380.4923\n",
      "BART RMSE: 59574.0496\n"
     ]
    }
   ],
   "source": [
    "bart_mape = mean_absolute_percentage_error(y_test, y_pred_bart)\n",
    "bart_mae = mean_absolute_error(y_test, y_pred_bart)\n",
    "bart_mse = mean_squared_error(y_test, y_pred_bart)\n",
    "bart_rmse = rmse(y_test, y_pred_bart)\n",
    "\n",
    "print(\"BART MAPE:\", round(bart_mape, 4))\n",
    "print(\"BART MAE:\", round(bart_mae, 4))\n",
    "print(\"BART MSE:\", round(bart_mse, 4))\n",
    "print(\"BART RMSE:\", round(bart_rmse, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eeec9c",
   "metadata": {},
   "source": [
    "Slightly better results than Bagging in terms of RMSE, however it took an extraodinarly long time despite having a good CPU (7800X3D). Bagging also won out in t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
